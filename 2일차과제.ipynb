{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "73586d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cf61dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_breast_cancer()\n",
    "X = df.data\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fc5eda86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "af2dc862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#스플릿\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "10324fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "# 타겟값 이진분류니 형태변경,분리를 잘못넣어서 오류\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "#넘파이 배열 > 텐서 배열로 변환\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70b1a888",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "016d1cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "8a7c0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cancerclf(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Cancerclf,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr1 = nn.Linear(30,64) #입력 30개인데 32라써서 오류\n",
    "        self.lr2 = nn.Linear(64,32) #히든\n",
    "        self.lr3 = nn.Linear(32,1) #히든받고 출력\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr3(x)\n",
    "        return x #대문자 x써서 오류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f4ee19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Cancerclf().to(device)\n",
    "\n",
    "\n",
    "wtf = nn.BCEWithLogitsLoss()  # 손실 함수\n",
    "opti = optim.Adam(model.parameters(), lr =0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "1da6811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            opti.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # outputs: (N,1), labels: (N,1) 조건 필요\n",
    "            loss = wtf(outputs, labels)\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "519839d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs,labels in test_loader:\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuarcy = 100 * correct / total\n",
    "        print(f\"T정확도:{accuarcy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "44c826c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss: 0.5944\n",
      "Epoch [2/100] Loss: 0.2584\n",
      "Epoch [3/100] Loss: 0.1681\n",
      "Epoch [4/100] Loss: 0.1276\n",
      "Epoch [5/100] Loss: 0.0855\n",
      "Epoch [6/100] Loss: 0.1432\n",
      "Epoch [7/100] Loss: 0.1879\n",
      "Epoch [8/100] Loss: 0.0115\n",
      "Epoch [9/100] Loss: 0.0092\n",
      "Epoch [10/100] Loss: 0.0363\n",
      "Epoch [11/100] Loss: 0.0109\n",
      "Epoch [12/100] Loss: 0.0393\n",
      "Epoch [13/100] Loss: 0.0294\n",
      "Epoch [14/100] Loss: 0.0068\n",
      "Epoch [15/100] Loss: 0.0186\n",
      "Epoch [16/100] Loss: 0.0397\n",
      "Epoch [17/100] Loss: 0.4122\n",
      "Epoch [18/100] Loss: 0.0130\n",
      "Epoch [19/100] Loss: 0.0439\n",
      "Epoch [20/100] Loss: 0.0019\n",
      "Epoch [21/100] Loss: 0.0006\n",
      "Epoch [22/100] Loss: 0.0242\n",
      "Epoch [23/100] Loss: 0.0204\n",
      "Epoch [24/100] Loss: 0.0015\n",
      "Epoch [25/100] Loss: 0.2990\n",
      "Epoch [26/100] Loss: 0.0016\n",
      "Epoch [27/100] Loss: 0.0004\n",
      "Epoch [28/100] Loss: 0.0391\n",
      "Epoch [29/100] Loss: 0.0120\n",
      "Epoch [30/100] Loss: 0.0053\n",
      "Epoch [31/100] Loss: 0.0002\n",
      "Epoch [32/100] Loss: 0.0027\n",
      "Epoch [33/100] Loss: 0.0040\n",
      "Epoch [34/100] Loss: 0.0013\n",
      "Epoch [35/100] Loss: 0.0007\n",
      "Epoch [36/100] Loss: 0.0022\n",
      "Epoch [37/100] Loss: 0.0004\n",
      "Epoch [38/100] Loss: 0.0004\n",
      "Epoch [39/100] Loss: 0.0053\n",
      "Epoch [40/100] Loss: 0.0011\n",
      "Epoch [41/100] Loss: 0.0055\n",
      "Epoch [42/100] Loss: 0.0003\n",
      "Epoch [43/100] Loss: 0.0001\n",
      "Epoch [44/100] Loss: 0.0159\n",
      "Epoch [45/100] Loss: 0.0021\n",
      "Epoch [46/100] Loss: 0.0121\n",
      "Epoch [47/100] Loss: 0.0000\n",
      "Epoch [48/100] Loss: 0.0039\n",
      "Epoch [49/100] Loss: 0.0059\n",
      "Epoch [50/100] Loss: 0.0018\n",
      "Epoch [51/100] Loss: 0.0005\n",
      "Epoch [52/100] Loss: 0.0054\n",
      "Epoch [53/100] Loss: 0.0005\n",
      "Epoch [54/100] Loss: 0.0011\n",
      "Epoch [55/100] Loss: 0.0000\n",
      "Epoch [56/100] Loss: 0.0010\n",
      "Epoch [57/100] Loss: 0.0010\n",
      "Epoch [58/100] Loss: 0.0009\n",
      "Epoch [59/100] Loss: 0.0274\n",
      "Epoch [60/100] Loss: 0.0060\n",
      "Epoch [61/100] Loss: 0.0000\n",
      "Epoch [62/100] Loss: 0.0000\n",
      "Epoch [63/100] Loss: 0.0002\n",
      "Epoch [64/100] Loss: 0.0009\n",
      "Epoch [65/100] Loss: 0.0000\n",
      "Epoch [66/100] Loss: 0.0164\n",
      "Epoch [67/100] Loss: 0.0151\n",
      "Epoch [68/100] Loss: 0.0003\n",
      "Epoch [69/100] Loss: 0.0001\n",
      "Epoch [70/100] Loss: 0.0350\n",
      "Epoch [71/100] Loss: 0.0029\n",
      "Epoch [72/100] Loss: 0.0000\n",
      "Epoch [73/100] Loss: 0.0000\n",
      "Epoch [74/100] Loss: 0.0001\n",
      "Epoch [75/100] Loss: 0.0000\n",
      "Epoch [76/100] Loss: 0.0013\n",
      "Epoch [77/100] Loss: 0.0008\n",
      "Epoch [78/100] Loss: 0.0037\n",
      "Epoch [79/100] Loss: 0.0000\n",
      "Epoch [80/100] Loss: 0.0000\n",
      "Epoch [81/100] Loss: 0.0011\n",
      "Epoch [82/100] Loss: 0.0005\n",
      "Epoch [83/100] Loss: 0.0029\n",
      "Epoch [84/100] Loss: 0.0005\n",
      "Epoch [85/100] Loss: 0.0000\n",
      "Epoch [86/100] Loss: 0.0000\n",
      "Epoch [87/100] Loss: 0.0001\n",
      "Epoch [88/100] Loss: 0.0001\n",
      "Epoch [89/100] Loss: 0.0000\n",
      "Epoch [90/100] Loss: 0.0000\n",
      "Epoch [91/100] Loss: 0.0000\n",
      "Epoch [92/100] Loss: 0.0001\n",
      "Epoch [93/100] Loss: 0.0002\n",
      "Epoch [94/100] Loss: 0.0000\n",
      "Epoch [95/100] Loss: 0.0000\n",
      "Epoch [96/100] Loss: 0.0000\n",
      "Epoch [97/100] Loss: 0.0000\n",
      "Epoch [98/100] Loss: 0.0002\n",
      "Epoch [99/100] Loss: 0.0002\n",
      "Epoch [100/100] Loss: 0.0000\n",
      "T정확도:96.49%\n"
     ]
    }
   ],
   "source": [
    "train_model(epochs=100)\n",
    "evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b28dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75865148",
   "metadata": {},
   "source": [
    "# 윤년"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe7c6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLeap(year): \n",
    "    if year%4 == 0 and year%100!=0 or year%400==0: # %는 나머지 연산자. and로 두가지중 하나가 만족하거나 다른 1가지가 만족하면 윤년. 값이 4년이거나 100년이아닐때, 400년이 지날때\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f85bc8",
   "metadata": {},
   "source": [
    "1~4000까지의 데이터를 훈련데이터로 하고 그 이후의 1000을 테스트 데이터로 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c449af2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =np.array([i for i in range(1,4001)])\n",
    "y_train = np.array([isLeap(i) for i in X_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9fde1317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([i for i in range (4001,5001)])\n",
    "y_test = np.array([isLeap(i) for i in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0904788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 1)\n",
    "X_test = X_test.reshape(-1, 1)\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "#넘파이 배열 > 텐서 배열로 변환\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "test_dataset = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3d55977f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100] Loss: 0.5569\n",
      "Epoch [2/100] Loss: 0.7354\n",
      "Epoch [3/100] Loss: 0.6496\n",
      "Epoch [4/100] Loss: 0.5909\n",
      "Epoch [5/100] Loss: 0.5149\n",
      "Epoch [6/100] Loss: 0.6912\n",
      "Epoch [7/100] Loss: 0.5448\n",
      "Epoch [8/100] Loss: 0.5067\n",
      "Epoch [9/100] Loss: 0.7530\n",
      "Epoch [10/100] Loss: 0.5688\n",
      "Epoch [11/100] Loss: 0.6009\n",
      "Epoch [12/100] Loss: 0.6235\n",
      "Epoch [13/100] Loss: 0.5918\n",
      "Epoch [14/100] Loss: 0.5649\n",
      "Epoch [15/100] Loss: 0.5284\n",
      "Epoch [16/100] Loss: 0.4630\n",
      "Epoch [17/100] Loss: 0.6302\n",
      "Epoch [18/100] Loss: 0.5813\n",
      "Epoch [19/100] Loss: 0.6830\n",
      "Epoch [20/100] Loss: 0.6703\n",
      "Epoch [21/100] Loss: 0.7307\n",
      "Epoch [22/100] Loss: 0.4868\n",
      "Epoch [23/100] Loss: 0.5630\n",
      "Epoch [24/100] Loss: 0.4924\n",
      "Epoch [25/100] Loss: 0.4514\n",
      "Epoch [26/100] Loss: 0.5586\n",
      "Epoch [27/100] Loss: 0.4941\n",
      "Epoch [28/100] Loss: 0.7033\n",
      "Epoch [29/100] Loss: 0.6687\n",
      "Epoch [30/100] Loss: 0.4940\n",
      "Epoch [31/100] Loss: 0.4567\n",
      "Epoch [32/100] Loss: 0.4578\n",
      "Epoch [33/100] Loss: 0.7050\n",
      "Epoch [34/100] Loss: 0.5284\n",
      "Epoch [35/100] Loss: 0.4563\n",
      "Epoch [36/100] Loss: 0.5269\n",
      "Epoch [37/100] Loss: 0.6331\n",
      "Epoch [38/100] Loss: 0.5270\n",
      "Epoch [39/100] Loss: 0.5268\n",
      "Epoch [40/100] Loss: 0.5626\n",
      "Epoch [41/100] Loss: 0.4909\n",
      "Epoch [42/100] Loss: 0.5986\n",
      "Epoch [43/100] Loss: 0.5265\n",
      "Epoch [44/100] Loss: 0.5625\n",
      "Epoch [45/100] Loss: 0.4541\n",
      "Epoch [46/100] Loss: 0.5266\n",
      "Epoch [47/100] Loss: 0.3873\n",
      "Epoch [48/100] Loss: 0.5265\n",
      "Epoch [49/100] Loss: 0.6348\n",
      "Epoch [50/100] Loss: 0.5268\n",
      "Epoch [51/100] Loss: 0.4207\n",
      "Epoch [52/100] Loss: 0.5272\n",
      "Epoch [53/100] Loss: 0.6340\n",
      "Epoch [54/100] Loss: 0.5264\n",
      "Epoch [55/100] Loss: 0.5625\n",
      "Epoch [56/100] Loss: 0.5978\n",
      "Epoch [57/100] Loss: 0.3883\n",
      "Epoch [58/100] Loss: 0.4543\n",
      "Epoch [59/100] Loss: 0.6330\n",
      "Epoch [60/100] Loss: 0.6683\n",
      "Epoch [61/100] Loss: 0.6698\n",
      "Epoch [62/100] Loss: 0.5982\n",
      "Epoch [63/100] Loss: 0.6689\n",
      "Epoch [64/100] Loss: 0.5625\n",
      "Epoch [65/100] Loss: 0.3851\n",
      "Epoch [66/100] Loss: 0.4534\n",
      "Epoch [67/100] Loss: 0.7062\n",
      "Epoch [68/100] Loss: 0.6695\n",
      "Epoch [69/100] Loss: 0.5634\n",
      "Epoch [70/100] Loss: 0.6697\n",
      "Epoch [71/100] Loss: 0.4912\n",
      "Epoch [72/100] Loss: 0.6338\n",
      "Epoch [73/100] Loss: 0.5269\n",
      "Epoch [74/100] Loss: 0.7034\n",
      "Epoch [75/100] Loss: 0.6330\n",
      "Epoch [76/100] Loss: 0.5976\n",
      "Epoch [77/100] Loss: 0.7043\n",
      "Epoch [78/100] Loss: 0.6692\n",
      "Epoch [79/100] Loss: 0.4556\n",
      "Epoch [80/100] Loss: 0.5273\n",
      "Epoch [81/100] Loss: 0.5267\n",
      "Epoch [82/100] Loss: 0.5625\n",
      "Epoch [83/100] Loss: 0.6341\n",
      "Epoch [84/100] Loss: 0.5980\n",
      "Epoch [85/100] Loss: 0.5266\n",
      "Epoch [86/100] Loss: 0.5264\n",
      "Epoch [87/100] Loss: 0.4561\n",
      "Epoch [88/100] Loss: 0.4212\n",
      "Epoch [89/100] Loss: 0.4923\n",
      "Epoch [90/100] Loss: 0.4562\n",
      "Epoch [91/100] Loss: 0.4175\n",
      "Epoch [92/100] Loss: 0.4901\n",
      "Epoch [93/100] Loss: 0.4927\n",
      "Epoch [94/100] Loss: 0.4553\n",
      "Epoch [95/100] Loss: 0.4549\n",
      "Epoch [96/100] Loss: 0.4567\n",
      "Epoch [97/100] Loss: 0.7361\n",
      "Epoch [98/100] Loss: 0.5624\n",
      "Epoch [99/100] Loss: 0.5980\n",
      "Epoch [100/100] Loss: 0.4934\n",
      "T정확도:75.80%\n"
     ]
    }
   ],
   "source": [
    "#암환자 모델 고쳐쓰기\n",
    "class year_leap(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(year_leap,self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lr1 = nn.Linear(1,3)\n",
    "        self.lr2 = nn.Linear(3,24) \n",
    "        self.lr3 = nn.Linear(24,1) \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.lr1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lr3(x)\n",
    "        return x #대문자 x써서 오류\n",
    "    \n",
    "\n",
    "model = year_leap().to(device)\n",
    "\n",
    "\n",
    "wtf = nn.BCEWithLogitsLoss()  # 손실 함수\n",
    "opti = optim.Adam(model.parameters(), lr =0.001)\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def train_model(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            opti.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # outputs: (N,1), labels: (N,1) 조건 필요\n",
    "            loss = wtf(outputs, labels)\n",
    "            loss.backward()\n",
    "            opti.step()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f}\")\n",
    "\n",
    "def evaluate_model():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs,labels in test_loader:\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            predicted = torch.round(torch.sigmoid(outputs))\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuarcy = 100 * correct / total\n",
    "        print(f\"T정확도:{accuarcy:.2f}%\")\n",
    "\n",
    "train_model(epochs=100)\n",
    "evaluate_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c7f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff9cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
