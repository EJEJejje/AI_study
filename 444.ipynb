{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebeacec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image as pilimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9685da",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = pilimg.open(\"./images/cat1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53500819",
   "metadata": {},
   "outputs": [],
   "source": [
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "966bf20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix = np.array(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d5ddca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]\n",
      "\n",
      " [[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]\n",
      "\n",
      " [[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]\n",
      "\n",
      " [[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]\n",
      "\n",
      " [[ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  [ 28  28  28]\n",
      "  ...\n",
      "  [237 241 244]\n",
      "  [237 241 244]\n",
      "  [237 241 244]]]\n"
     ]
    }
   ],
   "source": [
    "print(pix[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df412c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(630, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "print(pix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e0343d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'module'>\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow.keras as keras \n",
    "from tensorflow.keras.datasets import mnist \n",
    "import PIL.Image as pilimg\n",
    "\n",
    "print(type(mnist) ) \n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels)=mnist.load_data() \n",
    "print( train_images.shape ) # 28 by 28 이미지가 60000개 있음 \n",
    "\n",
    "#앞에 천개만 image1.jpg image2.jpg 형태로 저장하기 \n",
    "for i in range(1000):\n",
    "    pilimg.fromarray(train_images[i]).save(\"./images/numbers/image{}.png\".format(i))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f53c8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from PIL import Image as pilimg\n",
    "import imghdr\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ======================================================================\n",
    "# 1. 데이터 로딩 및 전처리 (Keras 코드와 동일)\n",
    "# ======================================================================\n",
    "\n",
    "# 데이터 만드는 수 \n",
    "def makeData(folder, label, isTrain):\n",
    "    if isTrain == 'train':\n",
    "        path = \"./data/flowers_/train/\" + folder\n",
    "    else:\n",
    "        path = \"./data/flowers_/test/\" + folder\n",
    "    data = [] \n",
    "    labels = [] \n",
    "    i=1 \n",
    "    for filename in os.listdir(path):\n",
    "        if i%10==0:\n",
    "            print(i)\n",
    "        i += 1\n",
    "        try: \n",
    "            kind = imghdr.what(path + \"/\" + filename)\n",
    "            if kind in [\"gif\", \"png\", \"jpeg\", \"jpg\"]:\n",
    "                img = pilimg.open(path + \"/\" + filename).convert('RGB') # PyTorch는 3채널 RGB를 선호\n",
    "                resize_img = img.resize((150, 150))\n",
    "                pixel = np.array(resize_img)\n",
    "                if pixel.shape==(150, 150, 3):\n",
    "                    data.append(pixel)\n",
    "                    labels.append(label)\n",
    "        except Exception as e:\n",
    "            print(f\"{filename} error: {e}\")\n",
    "\n",
    "    np.savez(\"imagedata{}.npz\".format(str(label) + '_' + isTrain), data=data, targets=labels)\n",
    "    print(\"파일저장완료\")\n",
    "\n",
    "    # makeData('daisy'    ,0,'train')\n",
    "    # makeData('dandelion',1,'train')\n",
    "    # makeData('rose'     ,2,'train')\n",
    "    # makeData('sunflower',3,'train')\n",
    "    # makeData('tulip'    ,4,'train')    \n",
    "\n",
    "    # makeData('daisy'    ,0,'train')\n",
    "    # makeData('dandelion',1,'train')\n",
    "    # makeData('rose'     ,2,'train')\n",
    "    # makeData('sunflower',3,'train')\n",
    "    # makeData('tulip'    ,4,'train')    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d68909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n",
      "파일저장완료\n"
     ]
    }
   ],
   "source": [
    "# # 이미 생성된 npz 파일이 있다고 가정하고 로딩하는 코드\n",
    "# # makeData 함수는 위 Keras 코드의 실행 결과와 동일한 데이터를 생성\n",
    "\n",
    "# def dataCreate():\n",
    "#     flowers = [\"daisy\", \"dandelion\", \"rose\", \"sunflower\", \"tulip\"]\n",
    "#     label=0 \n",
    "#     for flower in flowers:\n",
    "#         makeData(flower, label, 'train')\n",
    "#         makeData(flower, label, 'test')\n",
    "#         label += 1\n",
    "\n",
    "# def load_and_concat_data(mode):\n",
    "#     datas = []\n",
    "#     targets = []\n",
    "#     for label in range(5):\n",
    "#         npz_file = np.load(f\"imagedata{label}_{mode}.npz\")\n",
    "#         datas.append(npz_file[\"data\"])\n",
    "#         targets.append(npz_file[\"targets\"])\n",
    "    \n",
    "#     return np.concatenate(datas, axis=0), np.concatenate(targets, axis=0)\n",
    "\n",
    "# dataCreate()\n",
    "\n",
    "# trainData_np, trainTarget_np = load_and_concat_data('train')\n",
    "# testData_np, testTarget_np = load_and_concat_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84dd38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: torch.Size([3027, 3, 150, 150])\n",
      "Test Data Shape: torch.Size([1296, 3, 150, 150])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 데이터 형태 변환 (PyTorch에 맞게)\n",
    "# PyTorch는 `channels_first` (C, H, W) 형태를 선호합니다.\n",
    "# 데이터 정규화: 0-255 -> 0.0-1.0\n",
    "trainData_tensor = torch.from_numpy(trainData_np).float().permute(0, 3, 1, 2) / 255.0\n",
    "testData_tensor = torch.from_numpy(testData_np).float().permute(0, 3, 1, 2) / 255.0\n",
    "\n",
    "# PyTorch에서는 One-Hot Encoding을 사용하지 않고, CrossEntropyLoss에 정수 라벨을 바로 전달\n",
    "trainTarget_tensor = torch.from_numpy(trainTarget_np).long()\n",
    "testTarget_tensor = torch.from_numpy(testTarget_np).long()\n",
    "\n",
    "print(f\"Train Data Shape: {trainData_tensor.shape}\")\n",
    "print(f\"Test Data Shape: {testData_tensor.shape}\")\n",
    "\n",
    "# 데이터 로더 생성\n",
    "train_dataset = TensorDataset(trainData_tensor, trainTarget_tensor)\n",
    "test_dataset = TensorDataset(testData_tensor, testTarget_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d1bc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=87616, out_features=256, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "  (fc4): Linear(in_features=32, out_features=5, bias=True)\n",
      ")\n",
      "Epoch 1/3, Loss: 1.6122\n",
      "Epoch 2/3, Loss: 1.6110\n",
      "Epoch 3/3, Loss: 1.6095\n",
      "\n",
      "훈련셋 정확도: 24.38%\n",
      "테스트셋 정확도: 27.01%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2. 모델 정의 (Fully-Connected Network)\n",
    "# ======================================================================\n",
    "\n",
    "# Keras의 Sequential 모델과 동일한 구조의 PyTorch 모델 정의\n",
    "# 입력 형태 (150*150*3) -> Dense(256) -> Dense(64) -> Dense(32) -> Dense(5)\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # (?, 3, 150,150) \n",
    "        #1단계\n",
    "        self.conv1 = nn.Conv2d( 3, 32, kernel_size=3,  stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d( kernel_size=2, stride=2)\n",
    "        #  150/2 = 75 by 75 \n",
    "\n",
    "        #2단계\n",
    "        self.conv2 = nn.Conv2d( 32, 64, kernel_size=3,  stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d( kernel_size=2, stride=2)\n",
    "        #  75/2= 37.5 = > 자름  37 by 37\n",
    "        # 64 *  37 *  37\n",
    "        self.fc_input_size =64 *  37 *  37\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 256) #150*150*3 -> 256 입력레이어\n",
    "        self.relu = nn.ReLU()   \n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 5) # 5개의 클래스 (daisy, dandelion, ...)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        #중간에 평탄화 작업 \n",
    "        x = x.view(-1, self.fc_input_size)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = SimpleCNN()\n",
    "print(model)\n",
    "\n",
    "# ======================================================================\n",
    "# 3. 모델 컴파일 및 학습\n",
    "# ======================================================================\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss() # Keras의 'categorical_crossentropy'와 동일\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01) # learning rate는 기본값으로 설정\n",
    "\n",
    "epochs = 3\n",
    "# 학습 루프\n",
    "for epoch in range(epochs):\n",
    "    model.train() # 모델을 학습 모드로 설정\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        # 그래디언트 초기화\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 (forward pass)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 역전파 (backward pass) 및 옵티마이저 스텝\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "\n",
    "# ======================================================================\n",
    "# 4. 모델 평가\n",
    "# ======================================================================\n",
    "\n",
    "# 모델을 평가 모드로 설정\n",
    "model.eval()\n",
    "train_correct = 0\n",
    "train_total = 0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "# 훈련셋 평가\n",
    "with torch.no_grad(): # 평가 시에는 그래디언트를 계산하지 않음\n",
    "    for inputs, labels in train_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# 테스트셋 평가\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        test_total += labels.size(0)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "train_acc = 100 * train_correct / train_total\n",
    "test_acc = 100 * test_correct / test_total\n",
    "\n",
    "print(f'\\n훈련셋 정확도: {train_acc:.2f}%')\n",
    "print(f'테스트셋 정확도: {test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdf1ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm # 학습 진행 상황 시각화를 위해 추가\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "# 이후 PyTorch, NumPy, TensorFlow 등을 import 합니다.\n",
    "# 경고 무시 설정\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e0fb75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. 경로 설정 및 하이퍼파라미터\n",
    "original_dataset_dir = './data/cats_and_dogs/train'\n",
    "base_dir = './data/cats_and_dogs_small'\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "model_save_path_pth = 'cats_and_dogs_model.pth'\n",
    "history_filepath = 'cats_and_dogs_history.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95a519fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사용 중인 디바이스: cpu\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "img_height = 180\n",
    "img_width = 180\n",
    "num_epochs = 30 # 예시로 epoch 수를 30으로 설정했습니다.\n",
    "learning_rate = 0.001 # learning_rate 추가\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"사용 중인 디바이스: {device}\")\n",
    "\n",
    "# 이미지 복사 함수 \n",
    "def ImageCopyMove():\n",
    "    if os.path.exists(base_dir):\n",
    "        shutil.rmtree(base_dir, ignore_errors=True)\n",
    "    os.makedirs(train_dir)\n",
    "    os.makedirs(validation_dir)\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "    train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "    train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "    validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "    validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "    test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "    test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "\n",
    "    os.makedirs(train_cats_dir)\n",
    "    os.makedirs(train_dogs_dir)\n",
    "    os.makedirs(validation_cats_dir)\n",
    "    os.makedirs(validation_dogs_dir)\n",
    "    os.makedirs(test_cats_dir)\n",
    "    os.makedirs(test_dogs_dir)\n",
    "    \n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "        \n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(test_cats_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(train_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(validation_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    \n",
    "    fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
    "    for fname in fnames:\n",
    "        src = os.path.join(original_dataset_dir, fname)\n",
    "        dst = os.path.join(test_dogs_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    print(\"이미지 복사 및 폴더 생성 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba8a5be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.ImageCopyMove()>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageCopyMove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c8bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
